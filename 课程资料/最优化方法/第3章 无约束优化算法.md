# 第3章 无约束优化算法

## 引言

### “旅者下山”问题
在本章中，我们将从连续可微的无约束优化问题出发，认识并学习优化算法。
考虑优化问题：
$$
\min_{x} f_0(x)
$$
其中 $f_0(x): \mathbb{R}^n \to \mathbb{R}$ 在 $\text{dom } f_0 = \mathbb{R}^n$ 上连续可微，且其极小值 $p^*$ 和最优解 $x^*$ 存在。

我们可以将求解最优解 $x^*$ 的过程想象成一个“旅者下山”的问题：
*   **当前位置**：假设旅者当前处于某点 $x$ 处，$f_0(x)$ 代表此地的高度。
*   **决策过程**：为了到达山底（即最小值点），旅者在当前点 $x$ 处需要思考两件事：
    1.  **搜索方向 (Search Direction)**：下一步该向哪个方向走才能下山？
    2.  **迭代步长 (Step Size)**：沿着这个方向走多远后停下来，以便选取下一个下山方向？
*   **迭代**：旅者不断重复上述决策过程，确定行走方向和距离，直到最终到达 $f_0(x)$ 的最小值点。

### 迭代算法基本框架
大多数无约束优化算法都遵循以下基本迭代框架：

1.  **步1 (初始化)**：选取初始点 $x^0 \in \mathbb{R}^n$ 及其他相关参数，令迭代次数 $k=0$。
2.  **步2 (终止条件判断)**：验证是否满足停机准则（例如，梯度足够小、函数值变化足够小等）。如果满足，则停止迭代；否则，继续。
3.  **步3 (确定搜索方向)**：计算在当前点 $x^k$ 处的搜索方向 $d^k \in \mathbb{R}^n$。通常，我们要求 $d^k$ 是一个**下降方向**，即满足：
    $$
    (\nabla f_0(x^k))^\top d^k < 0
    $$
4.  **步4 (计算步长)**：计算迭代步长 $\alpha_k \ge 0$。通常要求步长能使目标函数值下降，即：
    $$
    f_0(x^k + \alpha_k d^k) < f_0(x^k)
    $$
5.  **步5 (更新迭代点)**：产生下一个迭代点：
    $$
    x^{k+1} := x^k + \alpha_k d^k
    $$
    然后令 $k := k+1$，转到**步2**。

> 这个框架的核心思想是“先确定去哪儿（搜索方向），再决定走多远（迭代步长）”。其中，搜索方向的选取方法有梯度类、牛顿类等；而寻找合适步长 $\alpha_k$ 的过程，本质上是一个一维优化问题，通常称为**线搜索 (line search)**。

## 线搜索

线搜索的目标是在给定当前点 $x^k$ 和搜索方向 $d^k$ 后，寻找一个合适的步长 $\alpha_k$，使得目标函数值 $f_0(x^k + \alpha_k d^k)$ 尽可能小。

为方便讨论，我们定义一个关于 $\alpha$ 的一维辅助函数：
$$
\phi(\alpha) := f_0(x^k + \alpha d^k)
$$
线搜索的目标就是寻找一个合适的 $\alpha_k > 0$，使得 $\phi(\alpha_k) < \phi(0)$，并且使 $\phi(\alpha)$ 尽可能小。

### 精确线搜索 (Exact Line Search)
精确线搜索旨在找到最优的步长，即求解以下一维优化问题：
$$
\alpha_k = \arg\min_{\alpha \ge 0} \phi(\alpha)
$$
> 通俗地说，就是在选定的方向上一直走，直到找到那个方向上的最低点才停下来。

**常用方法**：
*   **二分法 (Bisection Method)**：
    若 $\phi(\alpha)$ 连续可微且为单峰函数（在 $(0, \infty)$ 内有唯一极小点），我们可以通过求解 $\phi'(\alpha) = 0$ 来找到最优步长。二分法步骤如下：
    1.  **初始化**：找到一个区间 $[a, b]$ (如 $a=0, b>0$)，使得 $\phi'(a)$ 和 $\phi'(b)$ 异号。
    2.  **迭代**：
        *   取中点 $c = \frac{a+b}{2}$，计算 $\phi'(c)$。
        *   若 $\phi'(c)$ 与 $\phi'(a)$ 同号，则更新 $a := c$。
        *   若 $\phi'(c)$ 与 $\phi'(b)$ 同号，则更新 $b := c$。
    3.  **终止**：当区间 $[a,b]$ 足够小或 $|\phi'(c)|$ 满足精度要求时，终止迭代。

*   **黄金分割法 (Golden Section Method)**：
    当 $\phi(\alpha)$ 的导数不易求解时，可采用黄金分割法。它同样适用于单峰函数，通过比较函数值来缩小最优解所在的区间。

**局限性**：
精确线搜索虽然理想，但在实际应用中，由于 $\phi(\alpha)$ 的形式往往很复杂，精确求解最优步长的计算代价非常高，甚至不切实际。因此，更常用的是非精确线搜索。

### 非精确线搜索 (Inexact Line Search)
非精确线搜索不追求找到最优步长，而是寻找一个“足够好”的步长，使其满足某些准则即可，从而在保证算法收敛的同时，降低计算开销。

#### Armijo 准则
Armijo 准则是最常用的线搜索准则之一，它要求步长 $\alpha_k$ 能带来**充分下降 (sufficient descent)**。具体来说，$\alpha_k$ 需要满足：
$$
f_0(x^k + \alpha_k d^k) \le f_0(x^k) + c_1 \alpha_k (\nabla f_0(x^k))^\top d^k
$$
其中 $c_1 \in (0, 1)$ 是一个常数（通常取很小的值，如 $c_1=10^{-3}$）。
![](综合知识复习/最优化原理/attachments/Pasted%20image%2020250819163104.png)
> **直观理解**：
> 我们可以画出函数 $\phi(\alpha)$ 的图像。$\phi(0) = f_0(x^k)$ 是起始点函数值。$\phi'(0) = (\nabla f_0(x^k))^\top d^k$ 是起始点的斜率。
> Armijo 准则构造了一条斜率为 $c_1 \phi'(0)$ 的直线 $l(\alpha) = \phi(0) + c_1 \alpha \phi'(0)$。由于 $d^k$ 是下降方向，$\phi'(0) < 0$，所以这条直线是向下倾斜的。Armijo 准则要求我们找到的 $\alpha_k$ 对应的函数值 $\phi(\alpha_k)$ 必须位于这条直线的下方。这保证了函数值的下降是“显著的”，而不仅仅是微小的下降，从而避免了步长过小导致进展缓慢。
>
> **寻找满足 Armijo 准则的步长 - 回退法 (Backtracking)**
> 一个常用的方法是回退法：
> 1.  **初始化**：选择一个初始步长 $\alpha$ (如 $\alpha=1$)，缩减比例 $\gamma \in (0, 1)$ (如 $\gamma = 0.5$)，以及参数 $c_1$。
> 2.  **循环**：
>     **while** $f_0(x^k + \alpha d^k) > f_0(x^k) + c_1 \alpha (\nabla f_0(x^k))^\top d^k$:
>     $\alpha := \gamma \alpha$
> 3.  **输出**：$\alpha_k = \alpha$。

#### Goldstein 准则
Armijo 准则只保证了函数值充分下降，但没有限制步长不能过小。Goldstein 准则通过增加一个下界条件来避免此问题。它要求 $\alpha_k$ 同时满足两个不等式：
$$
f_0(x^k) + (1-c) \alpha_k (\nabla f_0(x^k))^\top d^k \le f_0(x^k + \alpha_k d^k) \le f_0(x^k) + c \alpha_k (\nabla f_0(x^k))^\top d^k
$$
其中 $0 < c < 1/2$。
![](综合知识复习/最优化原理/attachments/Pasted%20image%2020250819163146.png)
> **直观理解**：
> Goldstein 准则构造了两条直线，一条斜率是 $c \phi'(0)$，另一条是 $(1-c)\phi'(0)$。它要求 $\phi(\alpha_k)$ 的值必须落在这两条直线之间。这不仅保证了充分下降（上界），还防止了步长过小（下界）。

#### Wolfe 准则
Wolfe 准则在 Armijo 准则的基础上，增加了一个关于导数的“曲率条件”，以确保不会选择过小的步长。它要求 $\alpha_k$ 满足：
1.  **Armijo 准则 (充分下降条件)**：
    $$
    f_0(x^k + \alpha_k d^k) \le f_0(x^k) + c_1 \alpha_k (\nabla f_0(x^k))^\top d^k
    $$
2.  **曲率条件**：
    $$
    (\nabla f_0(x^k + \alpha_k d^k))^\top d^k \ge c_2 (\nabla f_0(x^k))^\top d^k
    $$
其中 $0 < c_1 < c_2 < 1$。
![](综合知识复习/最优化原理/attachments/Pasted%20image%2020250819163435.png)
> **直观理解**：
> 曲率条件的左边是 $\phi'(\alpha_k)$，右边是 $c_2 \phi'(0)$。由于 $\phi'(0)$ 是负数，这个条件要求新点的斜率 $\phi'(\alpha_k)$ 要比初始斜率 $\phi'(0)$ “更平缓”一些（即绝对值更小）。这排除了那些虽然满足 Armijo 准则但函数仍在急剧下降的点，间接鼓励了算法选择更接近一维极小点的步长。Wolfe 准则是很多高级优化算法（如拟牛顿法）中常用的线搜索准则。

### 基于线搜索的算法收敛性

#### 定理1 (Zoutendijk 定理)
假设目标函数 $f_0$ 有下界，且其梯度是 L-利普希茨连续 (L-Lipschitz continuous) 的，即存在常数 $L>0$ 使得：
$$
\|\nabla f_0(x) - \nabla f_0(y)\| \le L\|x - y\|, \quad \forall x, y \in \mathbb{R}^n
$$
如果我们采用满足 Wolfe 准则的线搜索方法，并且搜索方向 $d^k$ 始终是下降方向，那么有：
$$
\sum_{k=0}^{\infty} \cos^2 \theta_k \|\nabla f_0(x^k)\|^2 < +\infty
$$
其中 $\theta_k$ 是负梯度方向 $-\nabla f_0(x^k)$ 与搜索方向 $d^k$ 之间的夹角，即：
$$
\cos \theta_k = \frac{-\nabla f_0(x^k)^\top d^k}{\|\nabla f_0(x^k)\| \|d^k\|}
$$

> **直观理解**：
> Zoutendijk 定理是一个非常重要的基础性结论。它告诉我们，只要搜索方向 $d^k$ 不与负梯度方向“趋于正交”（即 $\cos \theta_k$ 不趋于0），那么为了使上述级数收敛，梯度的范数 $\|\nabla f_0(x^k)\|$ 必须趋于0。换句话说，算法产生的序列的梯度会趋于零，这意味着算法会收敛到一个驻点（对于凸问题，就是全局最优点）。这个定理为后续许多算法（如共轭梯度法、拟牛顿法）的全局收敛性提供了理论基础。

#### 推论1
基于 Zoutendijk 定理，如果我们的搜索方向始终与负梯度方向保持一个不小于某个正值的夹角余弦（即 $\cos \theta_k \ge \delta > 0$），那么可以保证：
$$
\lim_{k \to \infty} \|\nabla f_0(x^k)\| = 0
$$
算法收敛到驻点。

## 梯度类算法

梯度类算法是一类仅使用目标函数的一阶（梯度）信息来确定搜索方向的算法。

### 梯度下降法 (Gradient Descent)
梯度下降法是最简单、最基础的优化算法。它的核心思想是：在每一步迭代中，选择**负梯度方向**作为搜索方向。因为负梯度方向是函数值在局部下降最快的方向。
*   **搜索方向**：$d^k = -\nabla f_0(x^k)$
*   **迭代格式**：$x^{k+1} = x^k - \alpha_k \nabla f_0(x^k)$

其中，步长 $\alpha_k$ 可以通过线搜索确定，也可以采用固定步长、递减步长等策略。

### 梯度下降法的分析

#### 假设1 (梯度利普希茨连续)
函数 $f_0$ 的梯度是 L-利普希茨连续的，即存在 $L>0$ 使得：
$$
\|\nabla f_0(x) - \nabla f_0(y)\| \le L\|x - y\|
$$

> 这条假设限制了函数梯度的变化速度不能太快，意味着函数的曲率有一个上界。它等价于说（对于二阶可微函数）Hessian 矩阵的最大特征值有界，$\nabla^2 f_0(x) \preceq LI$。这个性质保证了我们可以用一个二次函数来很好地近似原函数。

#### 定理2 (收敛性 - 凸函数)
设 $f_0$ 是一个连续可微的凸函数，且其梯度是 L-利普希茨连续的。如果我们采用**固定步长** $\alpha_k = \alpha$，且步长满足 $0 < \alpha < 2/L$，那么梯度下降法产生的函数值序列 $\{f_0(x^k)\}$ 会收敛到最优值 $f_0(x^*)$，且收敛速率为：
$$
f_0(x^k) - f_0(x^*) \le \frac{\|x^0 - x^*\|^2}{2\alpha k}
$$
收敛速率为 $O(1/k)$，这被称为**次线性收敛 (sublinear convergence)**。

> **直观理解**：
> 这个定理告诉我们，对于光滑的凸函数，只要步长选得不太大（小于 $2/L$），梯度下降法就一定能收敛。但是收敛速度比较慢，是 $O(1/k)$ 的级别。例如，要把误差降到原来的 $1/10$，迭代次数大约也需要增加 10 倍。

#### 假设2 (强凸性)
函数 $f_0$ 是 $\mu$-强凸的，即存在 $\mu > 0$ 使得：
$$
f_0(y) \ge f_0(x) + \nabla f_0(x)^\top (y-x) + \frac{\mu}{2} \|y-x\|^2
$$

> 强凸性比普通凸性要求更高。它要求函数不仅是凸的，而且具有一定的“弯曲程度”。一个二次函数 $f(x)=\frac{1}{2}x^\top A x$ 是强凸的，当且仅当矩阵 $A$ 的最小特征值大于零。这个性质保证了函数有一个唯一的最小值点，并且在最小值点附近，函数形状像一个“碗”，不会过于平坦。

#### 定理3 (收敛性 - 强凸函数)
设 $f_0$ 是一个 $\mu$-强凸且其梯度是 L-利普希茨连续的函数。如果我们采用固定步长 $\alpha_k=\alpha$，且满足 $0 < \alpha \le 2/(\mu+L)$，那么梯度下降法产生的点列 $\{x^k\}$ 会收敛到唯一的最优解 $x^*$，并且收敛速率为：
$$
\|x^{k+1} - x^*\|^2 \le \left(1 - \frac{2\alpha\mu L}{\mu+L}\right) \|x^k - x^*\|^2
$$
收敛速率是 $O(c^k)$ 的，其中 $c = (1 - \frac{2\alpha\mu L}{\mu+L}) < 1$。这被称为**线性收敛 (linear convergence)**。

> **直观理解**：
> 当函数满足更强的强凸条件时，梯度下降法的收敛速度会从次线性提升到线性。线性收敛意味着每迭代一次，与最优解的距离（或误差）都会乘以一个小于1的常数。这比次线性快得多。例如，如果 $c=0.9$，那么大约每22次迭代，误差就会降低一个数量级。

#### 对步长的思考
线性收敛率中的收敛因子 $c$ 依赖于 $\kappa = L/\mu$，这个值被称为**条件数 (condition number)**。
*   当 $\kappa=1$ 时（例如 $f(x)=x^2$），函数的等高线是圆形，梯度下降一步到位。
*   当 $\kappa \gg 1$ 时，函数的等高线是扁长的椭圆形，收敛因子 $c$ 接近于1，收敛会变得非常缓慢，迭代路径呈现“之”字形。

### 梯度下降法的另一种解释
梯度下降法可以被看作是在每一步迭代中，用一个简单的二次函数来近似原函数 $f_0(x)$，然后求解这个近似函数的最小值。
在 $x^k$ 附近，我们可以做如下近似：
$$
f_0(x) \approx f_0(x^k) + \nabla f_0(x^k)^\top (x - x^k) + \frac{1}{2\alpha} \|x - x^k\|^2
$$
求解这个近似函数的最小值点，得到：
$$
x^{k+1} = x^k - \alpha \nabla f_0(x^k)
$$
这正是梯度下降法的迭代格式。

## 梯度下降法的扩展

### 次梯度方法 (Subgradient Method)
当目标函数 $f_0(x)$ 是凸函数但**不可微**时（例如 $f(x)=|x|$），梯度不存在，梯度下降法失效。此时可以使用次梯度方法。

#### 定义1 (次梯度和次微分)
对于凸函数 $f_0$，向量 $v$ 称为 $f_0$ 在点 $x$ 处的**次梯度**，如果它满足：
$$
f_0(y) \ge f_0(x) + v^\top (y-x), \quad \forall y
$$
在点 $x$ 处所有次梯度的集合称为**次微分**，记作 $\partial f_0(x)$。
*   如果 $f_0$ 在 $x$ 处可微，则其次微分只包含一个元素，即梯度：$\partial f_0(x) = \{\nabla f_0(x)\}$。
*   $x^*$ 是 $f_0$ 的最优解的充要条件是 $0 \in \partial f_0(x^*)$。

**次梯度方法**：
与梯度下降法类似，只是用负次梯度方向替代负梯度方向：
*   **搜索方向**：$d^k = -v^k$，其中 $v^k \in \partial f_0(x^k)$
*   **迭代格式**：$x^{k+1} = x^k - \alpha_k v^k$

> **注意**：次梯度方向不一定是下降方向，所以次梯度方法产生的函数值序列 $\{f_0(x^k)\}$ 可能不是单调下降的。因此，需要记录并返回历史迭代中函数值最小的点。

#### 定理4 (次梯度方法的收敛性)
次梯度方法的收敛性通常较慢，且步长的选择非常关键，一般不采用固定步长。对于递减且满足特定条件的步长（如 $\sum \alpha_k = \infty, \sum \alpha_k^2 < \infty$），可以保证收敛，但收敛速率通常也是次线性的，如 $O(1/\sqrt{k})$。

### 坐标下降法 (Coordinate Descent Method)
当问题维度很高或者梯度计算复杂时，可以考虑坐标下降法。它是一种“分而治之”的策略。

**核心思想**：
在每次迭代中，不沿着所有维度变化，而是只选择**一个坐标轴**方向进行优化。
**迭代步骤**：
循环遍历所有坐标轴 $i=1, \dots, n$：
$$
x_i^{k+1} \leftarrow \arg\min_{x_i} f_0(x_1^{k+1}, \dots, x_{i-1}^{k+1}, x_i, x_{i+1}^k, \dots, x_n^k)
$$
**收敛性**：
*   若 $f_0$ 是**连续可微的凸函数**，坐标下降法收敛到全局最优点。
*   若 $f_0$ 是凸函数但**不可微**，算法可能收敛到一个非最优点。
![](综合知识复习/最优化原理/attachments/Pasted%20image%2020250819164403.png)
### 复合型优化问题与邻近梯度法
许多实际问题可以表示为如下复合形式：
$$
\min_x f_0(x) := g(x) + r(x)
$$
其中 $g(x)$ 是光滑的凸函数（如损失函数），$r(x)$ 是非光滑但结构简单的凸函数（如正则项 $L_1$ 范数）。
> **光滑函数**一般指的是**一阶可微且梯度连续**的函数，也就是函数的导数（梯度）存在且连续。
#### 定义3 (邻近算子)
对于函数 $r$ 和常数 $\alpha>0$，其**邻近算子 (proximal operator)** 定义为：
$$
\text{prox}_{\alpha r}(x) = \arg\min_u \left( r(u) + \frac{1}{2\alpha} \|u-x\|^2 \right)
$$
> **直观理解**：邻近算子是在点 $x$ 附近寻找一个点 $u$，这个点不仅使 $r(u)$ 的值较小，而且离 $x$ 不太远。参数 $\alpha$ 平衡了这两者。对于很多常用的正则项（如 $L_1, L_2$ 范数），邻近算子有解析解（闭式解），计算非常高效。

#### 邻近梯度法 (Proximal Gradient Method)
该方法结合了梯度下降和邻近算子：
1.  对光滑部分 $g(x)$ 进行一步梯度下降：$y = x^k - \alpha_k \nabla g(x^k)$。
2.  对非光滑部分 $r(x)$ 应用邻近算子：$x^{k+1} = \text{prox}_{\alpha_k r}(y)$。
合并为一步迭代格式：
$$
x^{k+1} = \text{prox}_{\alpha_k r} (x^k - \alpha_k \nabla g(x^k))
$$

#### 定理5 (邻近梯度法的收敛性)
若 $g(x)$ 的梯度是 L-利普希茨连续的，采用固定步长 $0 < \alpha \le 1/L$，邻近梯度法同样具有 $O(1/k)$ 的次线性收敛速率。

### 加速邻近梯度法 (Accelerated Method)
Nesterov 提出了一系列加速方法，通过引入**“惯性”或“动量” (momentum)** 的思想，可以显著提高收敛速度。

**核心思想**：
下一步的更新点不仅仅依赖于当前点的梯度，还利用了之前迭代的历史信息。迭代格式通常包含一个外推步骤：
$$
\begin{align*}
y^k &= x^k + \beta_k (x^k - x^{k-1}) \quad (\text{动量步}) \\
x^{k+1} &= \text{prox}_{\alpha_k r}(y^k - \alpha_k \nabla g(y^k)) \quad (\text{邻近梯度步})
\end{align*}
$$
其中 $\beta_k$ 是动量系数。著名的 **FISTA** (Fast Iterative Shrinkage-Thresholding Algorithm) 就是这类算法的代表。

**收敛速率**：
Nesterov 加速方法可以将收敛速率从 $O(1/k)$ 提升到 $O(1/k^2)$，这是一个巨大的改进。

## 牛顿类算法

牛顿类算法利用了函数的二阶信息（Hessian 矩阵），从而能更精确地把握函数的局部形状，实现更快的收敛。

### 牛顿法 (Newton's Method)
**核心思想**：
在当前点 $x^k$ 附近，用一个二次函数来近似目标函数 $f_0(x)$。这个二次近似是基于 $f_0(x)$ 在 $x^k$ 处的泰勒二阶展开：
$$
f_0(x^k+d) \approx f_0(x^k) + \nabla f_0(x^k)^\top d + \frac{1}{2} d^\top \nabla^2 f_0(x^k) d
$$
通过最小化这个二次模型来求解下降方向 $d^k$，即求解：
$$
\nabla^2 f_0(x^k) d^k = -\nabla f_0(x^k)
$$
这个方程被称为**牛顿方程**。解出的 $d^k$ 被称为**牛顿方向**。
*   **迭代格式 (经典牛顿法)**：
    $$
    x^{k+1} = x^k - (\nabla^2 f_0(x^k))^{-1} \nabla f_0(x^k)
    $$
    这相当于步长 $\alpha_k=1$。

#### 定理7 (经典牛顿法的局部收敛性)
若 $f_0$ 二阶连续可微，在最优点 $x^*$ 处 Hessian 矩阵 $\nabla^2 f_0(x^*) \succ 0$，且 Hessian 矩阵在 $x^*$ 附近是利普希茨连续的，那么只要初始点 $x^0$ 离 $x^*$ **足够近**，经典牛顿法将以 **Q-二次速率**收敛到 $x^*$。

> **直观理解**：二次收敛意味着每迭代一次，有效数字的位数大约翻一番，收敛速度极快。但是，这种快速收敛是有代价的：
> 1.  **局部收敛**：只有在离最优点很近时才能保证收敛。
> 2.  **计算代价高**：每一步都需要计算 Hessian 矩阵并求解一个线性方程组，当维度 $n$ 很大时，计算量巨大 ($O(n^3)$)。
> 3.  **Hessian 矩阵要求**：需要 Hessian 矩阵是正定的，否则牛顿方向可能不是下降方向。

**改进方法**：
*   **阻尼牛顿法 (Damped Newton Method)**：引入线搜索，即 $x^{k+1} = x^k + \alpha_k d^k$，其中 $\alpha_k \in (0,1]$，以保证全局收敛性。

### 拟牛顿法 (Quasi-Newton Method)
为了克服牛顿法计算 Hessian 矩阵逆的巨大开销，拟牛顿法应运而生。

**核心思想**：
不直接计算 Hessian 矩阵 $\nabla^2 f_0(x^k)$，而是通过每一步迭代中的梯度变化信息，构造一个**近似矩阵** $B_k$ 来替代 Hessian 矩阵（或 $H_k$ 来近似 Hessian 矩阵的逆）。
*   **迭代格式**：
    $$
    x^{k+1} = x^k - \alpha_k B_k^{-1} \nabla f_0(x^k)
    $$
*   **核心问题**：如何高效地更新近似矩阵 $B_k \to B_{k+1}$？
    著名的更新方法有 **DFP** 和 **BFGS** 算法，其中 BFGS 是目前最流行和最有效的拟牛顿算法之一。

> **特点**：
> 拟牛顿法成功地在梯度下降法（慢但廉价）和牛顿法（快但昂贵）之间取得了平衡。它只使用一阶梯度信息，但通过巧妙的矩阵更新，模拟了二阶信息，通常能实现**超线性收敛**，比线性收敛快，但比二次收敛慢，同时计算代价远低于牛顿法。